{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-28T08:35:16.803796Z",
     "start_time": "2024-04-28T08:35:16.801473Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "from torchvision.transforms import v2\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.utils.parametrize as parametrize\n",
    "import torch.utils.data as tdata\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from random import sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [],
   "source": [
    "# Convert the grayscale images to binary images\n",
    "class Binarize(object):\n",
    "    def __init__(self, threshold):\n",
    "        self.threshold = threshold / 255\n",
    "\n",
    "    def __call__(self, img):\n",
    "        return (img > self.threshold).to(img.dtype)\n",
    "\n",
    "\n",
    "# Down sampling the images from 28x28 to 7x7 and binarize them\n",
    "transforms = v2.Compose([\n",
    "    v2.Resize((7, 7), antialias=False),\n",
    "    v2.ToDtype(torch.int8, scale=True),\n",
    "    Binarize(128),\n",
    "])\n",
    "\n",
    "train = datasets.MNIST(root='./data', train=True, download=True)\n",
    "test = datasets.MNIST(root='./data', train=False, download=True)\n",
    "\n",
    "# Overwriting train and test dataset just with '0' and '1' classes\n",
    "train.data = train.data[train.targets <= 1]\n",
    "train.targets = train.targets[train.targets <= 1]\n",
    "\n",
    "test.data = test.data[test.targets <= 1]\n",
    "test.targets = test.targets[test.targets <= 1]\n",
    "\n",
    "# Not sure why the 'transforms' is not getting applied above\n",
    "train.data = transforms(train.data)\n",
    "test.data = transforms(test.data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-28T08:32:05.931065Z",
     "start_time": "2024-04-28T08:32:05.788154Z"
    }
   },
   "id": "f312874bc31ca2b4"
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(1135)"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(test.targets == 1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-28T06:27:25.275073Z",
     "start_time": "2024-04-28T06:27:25.213170Z"
    }
   },
   "id": "7cb869a8a3ebcf29"
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "data": {
      "text/plain": "2115"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test.targets)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-28T06:27:48.451462Z",
     "start_time": "2024-04-28T06:27:48.447378Z"
    }
   },
   "id": "470f419f3fb2b6fd"
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(980)"
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(test.targets == 0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-28T06:27:36.394384Z",
     "start_time": "2024-04-28T06:27:36.378189Z"
    }
   },
   "id": "6a8d92f9c85d5ff6"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 1500x300 with 5 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Viewing a few random samples from the transformed dataset\n",
    "\n",
    "fig, ax = plt.subplots(1, 5, figsize=(15, 3))\n",
    "\n",
    "for i, j in enumerate(sample(range(len(train.data)), 5)):\n",
    "    ax[i].imshow(train.data[j], cmap='gray')\n",
    "    ax[i].set_title(train.targets[j].item())\n",
    "    ax[i].axis('off')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-27T18:24:24.259529Z",
     "start_time": "2024-04-27T18:24:24.088614Z"
    }
   },
   "id": "80fc0527c522b1f6"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[0, 0, 0, 0, 0, 0, 0],\n        [0, 0, 0, 1, 1, 1, 0],\n        [0, 0, 1, 1, 1, 1, 0],\n        [0, 0, 1, 0, 0, 1, 0],\n        [0, 1, 0, 0, 1, 1, 0],\n        [0, 1, 1, 1, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0, 0]], dtype=torch.int8)"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.data[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-27T18:24:27.106468Z",
     "start_time": "2024-04-27T18:24:27.097700Z"
    }
   },
   "id": "1f9d607f8725f19"
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "class shiftedReLU(nn.ReLU):\n",
    "    def __init__(self, shift: float = 0.4, inplace: bool = False):\n",
    "        super(shiftedReLU, self).__init__(inplace)\n",
    "        self.shift = shift\n",
    "\n",
    "    def forward(self, input):\n",
    "        return F.relu(input - self.shift, self.inplace)\n",
    "\n",
    "\n",
    "# Defining the MLP architecture\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(49, 32)\n",
    "        self.fc2 = nn.Linear(32, 1)\n",
    "        self.srelu = shiftedReLU(shift=0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 49)\n",
    "        # x = F.relu(self.fc1(x))\n",
    "        x = self.srelu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-28T08:22:46.946846Z",
     "start_time": "2024-04-28T08:22:46.945093Z"
    }
   },
   "id": "63a8dd94ea8a454f"
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "data": {
      "text/plain": "MLP(\n  (fc1): Linear(in_features=49, out_features=32, bias=True)\n  (fc2): Linear(in_features=32, out_features=1, bias=True)\n  (srelu): shiftedReLU()\n)"
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading the model\n",
    "\n",
    "# DEVICE = 'cuda' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu'\n",
    "DEVICE = 'cpu'\n",
    "model = MLP()\n",
    "model.load_state_dict(torch.load('models/fp32_clipped.pth'))\n",
    "model.to(DEVICE)\n",
    "model.eval()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-28T08:23:02.953277Z",
     "start_time": "2024-04-28T08:23:02.920183Z"
    }
   },
   "id": "6553a7c9ee9a8a1d"
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.395127296447754\n",
      "0.0\n",
      "0.0\n",
      "6.395127296447754\n",
      "0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 1500x300 with 5 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Viewing the Predictions\n",
    "\n",
    "fig, ax = plt.subplots(1, 5, figsize=(15, 3))\n",
    "\n",
    "for i, j in enumerate(sample(range(len(test.data)), 5)):\n",
    "    data, target = test.data[j].float().to(DEVICE), test.targets[j].float().to(DEVICE)\n",
    "    output = model(data)\n",
    "    print(output.item())\n",
    "    predicted = (output > 0).float()\n",
    "    ax[i].imshow(test.data[j], cmap='gray')\n",
    "    ax[i].set_title(f'True: {target.item()} | Pred: {predicted.item()}')\n",
    "    ax[i].axis('off')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-28T08:24:27.445890Z",
     "start_time": "2024-04-28T08:24:27.279356Z"
    }
   },
   "id": "8b4c1e3ef18cedf4"
  },
  {
   "cell_type": "markdown",
   "source": [
    "99.72%"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ef2402466ae0fa2a"
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fc1.weight Parameter containing:\n",
      "tensor([[0.0060, 0.1493, 0.0000,  ..., 0.1834, 0.0000, 0.0000],\n",
      "        [0.0609, 0.2453, 0.0000,  ..., 0.2185, 0.0000, 0.0152],\n",
      "        [0.0944, 0.0000, 1.0056,  ..., 0.3372, 0.0000, 0.0413],\n",
      "        ...,\n",
      "        [0.0394, 0.2407, 0.0000,  ..., 0.2485, 0.0000, 0.1242],\n",
      "        [0.1106, 0.1386, 0.0000,  ..., 0.2228, 0.0085, 0.0627],\n",
      "        [0.0843, 0.2027, 0.0000,  ..., 0.2490, 0.0000, 0.0347]],\n",
      "       requires_grad=True)\n",
      "fc1.bias Parameter containing:\n",
      "tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0018,\n",
      "        0.0646, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0364, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000], requires_grad=True)\n",
      "fc2.weight Parameter containing:\n",
      "tensor([[0.0000, 0.0000, 0.9422, 0.0000, 0.0000, 0.0000, 0.0000, 0.0875, 1.5634,\n",
      "         0.1311, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9456, 0.0000, 0.0947,\n",
      "         0.0913, 0.0225, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0029,\n",
      "         1.0297, 0.0000, 0.0000, 0.0000, 0.0000]], requires_grad=True)\n",
      "fc2.bias Parameter containing:\n",
      "tensor([0.], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# Print the weights of the model\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    print(name, param)\n",
    "    \n",
    "# Export the parameters as numpy arrays to a file"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-28T08:36:11.552918Z",
     "start_time": "2024-04-28T08:36:11.546371Z"
    }
   },
   "id": "2d2f39fef701aa5a"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Didn't find engine for operation quantized::linear_prepack NoQEngine",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[13], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# 8-bit quantization\u001B[39;00m\n\u001B[0;32m----> 3\u001B[0m model_int8 \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mao\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mquantization\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mquantize_dynamic\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m      4\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      5\u001B[0m \u001B[43m    \u001B[49m\u001B[43m{\u001B[49m\u001B[43mnn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mLinear\u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      6\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mqint8\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      8\u001B[0m torch\u001B[38;5;241m.\u001B[39msave(model_int8, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmodels/int8.pth\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[0;32m~/anaconda3/envs/PyTorch/lib/python3.11/site-packages/torch/ao/quantization/quantize.py:468\u001B[0m, in \u001B[0;36mquantize_dynamic\u001B[0;34m(model, qconfig_spec, dtype, mapping, inplace)\u001B[0m\n\u001B[1;32m    466\u001B[0m model\u001B[38;5;241m.\u001B[39meval()\n\u001B[1;32m    467\u001B[0m propagate_qconfig_(model, qconfig_spec)\n\u001B[0;32m--> 468\u001B[0m \u001B[43mconvert\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmapping\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minplace\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m    469\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m model\n",
      "File \u001B[0;32m~/anaconda3/envs/PyTorch/lib/python3.11/site-packages/torch/ao/quantization/quantize.py:553\u001B[0m, in \u001B[0;36mconvert\u001B[0;34m(module, mapping, inplace, remove_qconfig, is_reference, convert_custom_config_dict)\u001B[0m\n\u001B[1;32m    551\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m inplace:\n\u001B[1;32m    552\u001B[0m     module \u001B[38;5;241m=\u001B[39m copy\u001B[38;5;241m.\u001B[39mdeepcopy(module)\n\u001B[0;32m--> 553\u001B[0m \u001B[43m_convert\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    554\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmodule\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmapping\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minplace\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mis_reference\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_reference\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    555\u001B[0m \u001B[43m    \u001B[49m\u001B[43mconvert_custom_config_dict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconvert_custom_config_dict\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    556\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m remove_qconfig:\n\u001B[1;32m    557\u001B[0m     _remove_qconfig(module)\n",
      "File \u001B[0;32m~/anaconda3/envs/PyTorch/lib/python3.11/site-packages/torch/ao/quantization/quantize.py:593\u001B[0m, in \u001B[0;36m_convert\u001B[0;34m(module, mapping, inplace, is_reference, convert_custom_config_dict)\u001B[0m\n\u001B[1;32m    589\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(mod, _FusedModule) \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[1;32m    590\u001B[0m        type_before_parametrizations(mod) \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m custom_module_class_mapping:\n\u001B[1;32m    591\u001B[0m         _convert(mod, mapping, \u001B[38;5;28;01mTrue\u001B[39;00m,  \u001B[38;5;66;03m# inplace\u001B[39;00m\n\u001B[1;32m    592\u001B[0m                  is_reference, convert_custom_config_dict)\n\u001B[0;32m--> 593\u001B[0m     reassign[name] \u001B[38;5;241m=\u001B[39m \u001B[43mswap_module\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmod\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmapping\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcustom_module_class_mapping\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    595\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m key, value \u001B[38;5;129;01min\u001B[39;00m reassign\u001B[38;5;241m.\u001B[39mitems():\n\u001B[1;32m    596\u001B[0m     module\u001B[38;5;241m.\u001B[39m_modules[key] \u001B[38;5;241m=\u001B[39m value\n",
      "File \u001B[0;32m~/anaconda3/envs/PyTorch/lib/python3.11/site-packages/torch/ao/quantization/quantize.py:626\u001B[0m, in \u001B[0;36mswap_module\u001B[0;34m(mod, mapping, custom_module_class_mapping)\u001B[0m\n\u001B[1;32m    624\u001B[0m         new_mod \u001B[38;5;241m=\u001B[39m qmod\u001B[38;5;241m.\u001B[39mfrom_float(mod, weight_qparams)\n\u001B[1;32m    625\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 626\u001B[0m         new_mod \u001B[38;5;241m=\u001B[39m \u001B[43mqmod\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfrom_float\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmod\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    627\u001B[0m     swapped \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m    629\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m swapped:\n\u001B[1;32m    630\u001B[0m     \u001B[38;5;66;03m# Preserve module's pre forward hooks. They'll be called on quantized input\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/envs/PyTorch/lib/python3.11/site-packages/torch/ao/nn/quantized/dynamic/modules/linear.py:116\u001B[0m, in \u001B[0;36mLinear.from_float\u001B[0;34m(cls, mod)\u001B[0m\n\u001B[1;32m    114\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    115\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mUnsupported dtype specified for dynamic quantized Linear!\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m--> 116\u001B[0m qlinear \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mcls\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mmod\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43min_features\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmod\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mout_features\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    117\u001B[0m qlinear\u001B[38;5;241m.\u001B[39mset_weight_bias(qweight, mod\u001B[38;5;241m.\u001B[39mbias)\n\u001B[1;32m    118\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m qlinear\n",
      "File \u001B[0;32m~/anaconda3/envs/PyTorch/lib/python3.11/site-packages/torch/ao/nn/quantized/dynamic/modules/linear.py:40\u001B[0m, in \u001B[0;36mLinear.__init__\u001B[0;34m(self, in_features, out_features, bias_, dtype)\u001B[0m\n\u001B[1;32m     39\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, in_features, out_features, bias_\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, dtype\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mqint8):\n\u001B[0;32m---> 40\u001B[0m     \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__init__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43min_features\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mout_features\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbias_\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     41\u001B[0m     \u001B[38;5;66;03m# We don't muck around with buffers or attributes or anything here\u001B[39;00m\n\u001B[1;32m     42\u001B[0m     \u001B[38;5;66;03m# to keep the module simple. *everything* is simply a Python attribute.\u001B[39;00m\n\u001B[1;32m     43\u001B[0m     \u001B[38;5;66;03m# Serialization logic is explicitly handled in the below serialization and\u001B[39;00m\n\u001B[1;32m     44\u001B[0m     \u001B[38;5;66;03m# deserialization modules\u001B[39;00m\n\u001B[1;32m     45\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mversion \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m4\u001B[39m\n",
      "File \u001B[0;32m~/anaconda3/envs/PyTorch/lib/python3.11/site-packages/torch/ao/nn/quantized/modules/linear.py:151\u001B[0m, in \u001B[0;36mLinear.__init__\u001B[0;34m(self, in_features, out_features, bias_, dtype)\u001B[0m\n\u001B[1;32m    148\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    149\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mUnsupported dtype specified for quantized Linear!\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m--> 151\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_packed_params \u001B[38;5;241m=\u001B[39m \u001B[43mLinearPackedParams\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    152\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_packed_params\u001B[38;5;241m.\u001B[39mset_weight_bias(qweight, bias)\n\u001B[1;32m    153\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mscale \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1.0\u001B[39m\n",
      "File \u001B[0;32m~/anaconda3/envs/PyTorch/lib/python3.11/site-packages/torch/ao/nn/quantized/modules/linear.py:27\u001B[0m, in \u001B[0;36mLinearPackedParams.__init__\u001B[0;34m(self, dtype)\u001B[0m\n\u001B[1;32m     25\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdtype \u001B[38;5;241m==\u001B[39m torch\u001B[38;5;241m.\u001B[39mfloat16:\n\u001B[1;32m     26\u001B[0m     wq \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mzeros([\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m1\u001B[39m], dtype\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mfloat)\n\u001B[0;32m---> 27\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mset_weight_bias\u001B[49m\u001B[43m(\u001B[49m\u001B[43mwq\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/PyTorch/lib/python3.11/site-packages/torch/ao/nn/quantized/modules/linear.py:32\u001B[0m, in \u001B[0;36mLinearPackedParams.set_weight_bias\u001B[0;34m(self, weight, bias)\u001B[0m\n\u001B[1;32m     29\u001B[0m \u001B[38;5;129m@torch\u001B[39m\u001B[38;5;241m.\u001B[39mjit\u001B[38;5;241m.\u001B[39mexport\n\u001B[1;32m     30\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mset_weight_bias\u001B[39m(\u001B[38;5;28mself\u001B[39m, weight: torch\u001B[38;5;241m.\u001B[39mTensor, bias: Optional[torch\u001B[38;5;241m.\u001B[39mTensor]) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m     31\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdtype \u001B[38;5;241m==\u001B[39m torch\u001B[38;5;241m.\u001B[39mqint8:\n\u001B[0;32m---> 32\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_packed_params \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mops\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mquantized\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlinear_prepack\u001B[49m\u001B[43m(\u001B[49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbias\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     33\u001B[0m     \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdtype \u001B[38;5;241m==\u001B[39m torch\u001B[38;5;241m.\u001B[39mfloat16:\n\u001B[1;32m     34\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_packed_params \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mops\u001B[38;5;241m.\u001B[39mquantized\u001B[38;5;241m.\u001B[39mlinear_prepack_fp16(weight, bias)\n",
      "File \u001B[0;32m~/anaconda3/envs/PyTorch/lib/python3.11/site-packages/torch/_ops.py:854\u001B[0m, in \u001B[0;36mOpOverloadPacket.__call__\u001B[0;34m(self_, *args, **kwargs)\u001B[0m\n\u001B[1;32m    846\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(self_, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):  \u001B[38;5;66;03m# noqa: B902\u001B[39;00m\n\u001B[1;32m    847\u001B[0m     \u001B[38;5;66;03m# use `self_` to avoid naming collide with aten ops arguments that\u001B[39;00m\n\u001B[1;32m    848\u001B[0m     \u001B[38;5;66;03m# named \"self\". This way, all the aten ops can be called by kwargs.\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    852\u001B[0m     \u001B[38;5;66;03m# We save the function ptr as the `op` attribute on\u001B[39;00m\n\u001B[1;32m    853\u001B[0m     \u001B[38;5;66;03m# OpOverloadPacket to access it here.\u001B[39;00m\n\u001B[0;32m--> 854\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mself_\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_op\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43m{\u001B[49m\u001B[43m}\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mRuntimeError\u001B[0m: Didn't find engine for operation quantized::linear_prepack NoQEngine"
     ]
    }
   ],
   "source": [
    "# 8-bit quantization\n",
    "\n",
    "model_int8 = torch.ao.quantization.quantize_dynamic(\n",
    "    model,\n",
    "    {nn.Linear},\n",
    "    dtype=torch.qint8)\n",
    "\n",
    "torch.save(model_int8, 'models/int8.pth')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "332fa4bc4f616dd5"
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 80.57%\n"
     ]
    }
   ],
   "source": [
    "# Testing the clipped model\n",
    "\n",
    "test = tdata.TensorDataset(test.data.unsqueeze(1).float(), test.targets.float())\n",
    "test_loader = tdata.DataLoader(test, batch_size=64, shuffle=False)\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data, target in test_loader:\n",
    "        data, target = data.to(DEVICE), target.to(DEVICE)\n",
    "        output = model(data)\n",
    "        # print(output)\n",
    "        predicted = (output > 0).float()\n",
    "        total += target.size(0)\n",
    "        correct += (predicted == target.unsqueeze(1)).sum().item()\n",
    "\n",
    "print(f'Accuracy: {correct / total * 100:.2f}%')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-28T08:35:26.295922Z",
     "start_time": "2024-04-28T08:35:26.264239Z"
    }
   },
   "id": "e83a97284ac4e690"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
